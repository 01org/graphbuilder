GraphBuilder is a Java library for preparing graphs from large volume of any 
type of data from unstructured to structured. Graph structure plays a vital role
in various data analytics and structured machine learning applications. 
Processing large graphs requires distributed computing environment that creates 
multiple challenges for balanced systems. Balanced system requires careful 
preparation of graphs for the computation. GraphBuilder address these problem 
by encapsulating those details in a library written in Java using Apache Hadoop 
framework to achieve scalability. 


How to build the GraphBuilder?
------------------------------
GraphBuilder is using Maven for building the package, ensure maven is 
installed on the system. To build package type:
$> mvn package


How to use the GraphBuilder? 
----------------------------
GraphBuilder library can be used in multiple ways. Library groups multiple 
MapReduce jobs in four major groups: a) GraphCreation b) ComputeNetworkInfo 
c) GraphNormalization d) GraphPartitioning. These group can be chained 
depending on a particular graph construction requirements (e.g. Please refer
construction pipeline for link and doc-word graph in demoapps dir).  

Library can be used as tool to construct link and doc-word graph for Wikipedia
using following command:

Link graph construction - $> hadoop jar target/graphbuilder-0.0.1-SNAPSHOT-hadoop-job.jar com.intel.hadoop.graphbuilder.demoapps.wikipedia.linkgraph.LinkGraphEnd2End <# of partition> <hdfs input directory> <hdfs output directory>

Doc-word graph construction - $> hadoop jar target/graphbuilder-0.0.1-SNAPSHOT-hadoop-job.jar com.intel.hadoop.graphbuilder.demoapps.wikipedia.docwordgraph.TFIDFGraphEnd2End <# of partition> <hdfs input directory> <hdfs output directory> <optional stop word filter list>

Sample application code
----------------------- 
Early stage in graph building pipeline is data dependent, hence we abstracted 
out data dependent code from the library and provided interface to plug-in 
user code. Sample code for those interface can be found in following in 
demoapps directory. It contains code for generating link-graphs and doc-word 
graph out of Wikipedia XML dump. Interfaces are documented, please refer
a Javadoc in doc directory.
